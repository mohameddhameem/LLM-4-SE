import os
import xml.etree.ElementTree as ET
import torch
from torch_geometric.data import Data, InMemoryDataset
from glob import glob


def parse_graphml_to_pyg(graphml_path, global_label_to_idx=None):
    """
    Parse a GraphML file from Joern CPG export to PyTorch Geometric Data format.
    
    :param graphml_path: Path to the GraphML file
    :param global_label_to_idx: Optional global label to index mapping for consistent feature dimensions
    :return: PyG Data object
    """
    # Load original source code if available
    code_text = None
    code_file = graphml_path.replace('.graphml', '.txt')
    if os.path.exists(code_file):
        with open(code_file, 'r', encoding='utf-8') as f:
            code_text = f.read()
    
    tree = ET.parse(graphml_path)
    root = tree.getroot()
    
    # Namespace for GraphML
    ns = {'g': 'http://graphml.graphdrawing.org/xmlns'}
    
    # Get the graph element
    graph = root.find('g:graph', ns)
    if graph is None:
        raise ValueError("No graph found in GraphML")
    
    # Parse nodes
    nodes = {}
    node_features = []
    node_labels = []
    
    for i, node in enumerate(graph.findall('g:node', ns)):
        node_id = node.get('id')
        nodes[node_id] = i
        
        # Extract node label
        label_elem = node.find("g:data[@key='labelV']", ns)
        label = label_elem.text if label_elem is not None else "UNKNOWN"
        node_labels.append(label)
        
        # Collect all node attributes as features
        attrs = {}
        for data in node.findall('g:data', ns):
            key = data.get('key')
            value = data.text
            if value and key != 'labelV':
                attrs[key] = value
        
        node_features.append(attrs)
    
    # Parse edges
    edge_index = [[], []]
    edge_labels = []
    
    for edge in graph.findall('g:edge', ns):
        src = edge.get('source')
        dst = edge.get('target')
        
        if src in nodes and dst in nodes:
            edge_index[0].append(nodes[src])
            edge_index[1].append(nodes[dst])
            
            # Extract edge label
            label_elem = edge.find("g:data[@key='labelE']", ns)
            edge_label = label_elem.text if label_elem is not None else "UNKNOWN"
            edge_labels.append(edge_label)
    
    # Convert to PyG format
    edge_index = torch.tensor(edge_index, dtype=torch.long)
    
    # Create a simple node feature matrix (one-hot encoding of node labels)
    if global_label_to_idx is None:
        # Fallback: use local labels if no global mapping provided
        unique_labels = list(set(node_labels))
        label_to_idx = {label: idx for idx, label in enumerate(unique_labels)}
    else:
        # Use global label mapping for consistent feature dimensions
        label_to_idx = global_label_to_idx
        unique_labels = list(label_to_idx.keys())
    
    x = torch.zeros((len(nodes), len(unique_labels)), dtype=torch.float)
    for i, label in enumerate(node_labels):
        if label in label_to_idx:
            x[i, label_to_idx[label]] = 1.0
    
    # Store original labels and features as additional attributes
    data = Data(
        x=x,
        edge_index=edge_index,
        num_nodes=len(nodes),
        node_labels=node_labels,
        edge_labels=edge_labels,
        node_features=node_features,
        filename=os.path.basename(graphml_path),
        code=[code_text]
    )
    
    return data


class CPGDataset(InMemoryDataset):
    """
    PyTorch Geometric Dataset for CPG graphs from Joern.
    """
    def __init__(self, root='./CPG', transform=None, pre_transform=None):
        """
        :param root: Directory containing GraphML files
        :param transform: Optional transform to apply to each graph
        :param pre_transform: Optional pre-transform to apply to each graph
        """
        self.root_dir = root
        super().__init__(root, transform, pre_transform)
        self.data, self.slices = torch.load(self.processed_paths[0])
        # Load metadata (non-tensor attributes)
        metadata_path = self.processed_paths[0].replace('.pt', '_metadata.pt')
        if os.path.exists(metadata_path):
            self.metadata = torch.load(metadata_path)
        else:
            self.metadata = []
    
    @property
    def raw_file_names(self):
        """List of raw file names in the dataset."""
        graphml_files = glob(os.path.join(self.root_dir, "*.graphml"))
        return [os.path.basename(f) for f in graphml_files]
    
    @property
    def processed_file_names(self):
        """Name of the processed dataset file."""
        return ['cpg_dataset.pt']
    
    def download(self):
        """No download needed - files are generated by Joern."""
        pass
    
    def process(self):
        """Process GraphML files and save as PyG dataset."""
        data_list = []
        metadata_list = []
        
        graphml_files = glob(os.path.join(self.root_dir, 'graphml' ,"*.graphml"))
        print(f"Processing {len(graphml_files)} GraphML files...")
        
        # First pass: collect all unique node labels
        print("Collecting global node labels...")
        all_node_labels = set()
        for graphml_file in graphml_files:
            try:
                tree = ET.parse(graphml_file)
                root = tree.getroot()
                ns = {'g': 'http://graphml.graphdrawing.org/xmlns'}
                graph = root.find('g:graph', ns)
                if graph is not None:
                    for node in graph.findall('g:node', ns):
                        label_elem = node.find("g:data[@key='labelV']", ns)
                        label = label_elem.text if label_elem is not None else "UNKNOWN"
                        all_node_labels.add(label)
            except Exception as e:
                print(f"Warning: Could not scan {graphml_file}: {e}")
        
        # Create global label to index mapping
        global_label_to_idx = {label: idx for idx, label in enumerate(sorted(all_node_labels))}
        print(f"Found {len(global_label_to_idx)} unique node label types")
        
        # Second pass: parse all graphs with global label mapping
        for graphml_file in graphml_files:
            try:
                data = parse_graphml_to_pyg(graphml_file, global_label_to_idx=global_label_to_idx)
                
                # Extract metadata (non-tensor attributes)
                metadata = {
                    'code': data.code,
                    'filename': data.filename if hasattr(data, 'filename') else os.path.basename(graphml_file),
                    'node_labels': data.node_labels,
                    'edge_labels': data.edge_labels,
                    'node_features': data.node_features
                }
                metadata_list.append(metadata)
                
                # Remove non-tensor attributes before collate
                del data.code
                if hasattr(data, 'filename'):
                    del data.filename
                del data.node_labels
                del data.edge_labels
                del data.node_features
                
                if self.pre_transform is not None:
                    data = self.pre_transform(data)
                
                data_list.append(data)
                print(f"Processed {os.path.basename(graphml_file)}: {data.num_nodes} nodes, {data.edge_index.size(1)} edges")
            except Exception as e:
                print(f"Error processing {graphml_file}: {e}")
        
        # Save processed data
        data, slices = self.collate(data_list)
        torch.save((data, slices), self.processed_paths[0])
        
        # Save metadata separately
        metadata_path = self.processed_paths[0].replace('.pt', '_metadata.pt')
        torch.save(metadata_list, metadata_path)
        
        print(f"\nDataset saved to {self.processed_paths[0]}")
        print(f"Metadata saved to {metadata_path}")
    
    def get(self, idx):
        """Get a single graph with metadata."""
        data = super().get(idx)
        
        # Attach metadata
        if idx < len(self.metadata):
            meta = self.metadata[idx]
            data.code = meta.get('code')
            data.filename = meta.get('filename')
            data.node_labels = meta.get('node_labels')
            data.edge_labels = meta.get('edge_labels')
            data.node_features = meta.get('node_features')
        
        return data


def create_cpg_dataset(cpg_dir="./CPG", force_reload=False):
    """
    Create a PyG Dataset from CPG GraphML files.
    
    :param cpg_dir: Directory containing GraphML files
    :param force_reload: Force reprocessing even if processed file exists
    :return: CPGDataset object
    """
    # Remove processed files if force reload
    if force_reload:
        processed_file = os.path.join(cpg_dir, 'processed', 'cpg_dataset.pt')
        metadata_file = os.path.join(cpg_dir, 'processed', 'cpg_dataset_metadata.pt')
        
        if os.path.exists(processed_file):
            os.remove(processed_file)
            print(f"Removed existing processed file: {processed_file}")
        
        if os.path.exists(metadata_file):
            os.remove(metadata_file)
            print(f"Removed existing metadata file: {metadata_file}")
    
    dataset = CPGDataset(root=cpg_dir)
    print(f"\nDataset created: {len(dataset)} graphs")
    return dataset


if __name__ == "__main__":
    # Test the dataset creation
    dataset = create_cpg_dataset("./CPG", force_reload=True)
    
    if len(dataset) > 0:
        print(f"\nFirst graph:")
        print(dataset[0])
        print(f"\nSource code:\n{dataset[0].code[:200]}..." if dataset[0].code else "No code available")
        print(f"\nNode types: {set(dataset[0].node_labels[:10])}")
        print(f"Edge types: {set(dataset[0].edge_labels[:10])}")
